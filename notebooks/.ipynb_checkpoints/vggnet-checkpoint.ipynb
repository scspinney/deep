{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cd5ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from nilearn.image import index_img, smooth_img\n",
    "from nilearn.masking import apply_mask\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "import os\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, TensorDataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "from functools import partial\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import wandb\n",
    "import torchio as tio\n",
    "from nilearn.image import crop_img, resample_to_img\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "import warnings\n",
    "from typing import (\n",
    "    Callable,\n",
    "    ClassVar,\n",
    "    Dict,\n",
    "    Iterable,\n",
    "    List,\n",
    "    NamedTuple,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    Union,\n",
    "    Any\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7606af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_imbalance_sampler(labels):\n",
    "    # if type(labels) != torch.Tensor:\n",
    "    #     labels = torch.tensor(labels)\n",
    "    # print(labels.shape)\n",
    "\n",
    "    class_sample_count = torch.tensor(\n",
    "        [(labels == t).sum() for t in torch.unique(labels, sorted=True)])\n",
    "\n",
    "    print(f\"Class_count: {class_sample_count}\")\n",
    "\n",
    "    weight = 1. / class_sample_count.float()\n",
    "\n",
    "    samples_weight = torch.tensor([weight[t] for t in labels])\n",
    "\n",
    "    # Create sampler, dataset, loader\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight),replacement=True)\n",
    "\n",
    "    pos_weight = torch.tensor(class_sample_count[1] / (class_sample_count[0] + 1e-5), dtype=torch.float)\n",
    "\n",
    "    return sampler, weight\n",
    "\n",
    "class MRIDataModuleIO(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, labels: List[int], format: str, batch_size: int, augment: List[str],\n",
    "                 mask: str = '', file_paths: List[str] = None, num_workers: int = 1, sampler: bool=True):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = torch.tensor(labels)\n",
    "        self.format = format\n",
    "        self.n = len(labels)\n",
    "        self.n_train = int(.9*self.n)\n",
    "        self.n_test = self.n - self.n_train\n",
    "        self.mask = mask\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.file_paths = file_paths\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        shuffled_ind = np.random.choice(range(self.n),len(range(self.n)),replace=False)\n",
    "\n",
    "        self.train_labels = self.labels[shuffled_ind[:self.n_train]]\n",
    "        self.test_labels = self.labels[shuffled_ind[self.n_train:]]\n",
    "        self.train_paths = self.file_paths[shuffled_ind[:self.n_train]]\n",
    "        self.test_paths = self.file_paths[shuffled_ind[self.n_train:]]\n",
    "        self.sampler = sampler\n",
    "\n",
    "        # check test distribution\n",
    "        class_sample_count_test = torch.tensor(\n",
    "            [(self.test_labels == int(t)).sum() for t in torch.unique(self.labels, sorted=True)])\n",
    "\n",
    "        class_sample_count_train = torch.tensor(\n",
    "            [(self.train_labels == int(t)).sum() for t in torch.unique(self.labels, sorted=True)])\n",
    "\n",
    "        print(f\"Class distribution in test set: {class_sample_count_test}\")\n",
    "        print(f\"Class distribution in train set: {class_sample_count_train}\")\n",
    "\n",
    "\n",
    "    def get_max_shape(self, subjects):\n",
    "\n",
    "        preprocess = tio.Compose([\n",
    "            tio.EnsureShapeMultiple(2)\n",
    "        ])\n",
    "\n",
    "        dataset = tio.SubjectsDataset(subjects,transform=preprocess)\n",
    "        shapes = np.array([s.spatial_shape for s in dataset])\n",
    "        self.max_shape = shapes.max(axis=0)\n",
    "        return self.max_shape\n",
    "\n",
    "    def prepare_data(self):\n",
    "        image_training_paths = self.train_paths\n",
    "        label_training = self.train_labels\n",
    "        image_test_paths = self.test_paths\n",
    "        label_test = self.test_labels\n",
    "\n",
    "        self.subjects = []\n",
    "        for image_path, label in zip(image_training_paths, label_training):\n",
    "            # 'image' and 'label' are arbitrary names for the images\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(image_path),\n",
    "                label=label\n",
    "            )\n",
    "            self.subjects.append(subject)\n",
    "\n",
    "        self.test_subjects = []\n",
    "        for image_path,label in  zip(image_test_paths,label_test):\n",
    "            subject = tio.Subject(image=tio.ScalarImage(image_path),\n",
    "                                  label=label)\n",
    "            self.test_subjects.append(subject)\n",
    "\n",
    "    def get_preprocessing_transform(self):\n",
    "        preprocess = tio.Compose([\n",
    "            tio.CropOrPad(self.get_max_shape(self.subjects + self.test_subjects)),\n",
    "            tio.EnsureShapeMultiple(2),  \n",
    "            tio.RescaleIntensity((-1, 1)),\n",
    "        ])\n",
    "        return preprocess\n",
    "\n",
    "    def get_augmentation_transform(self):\n",
    "\n",
    "        if self.augment:\n",
    "            augment=[]\n",
    "            for a in self.augment:\n",
    "                if a == 'affine':\n",
    "                    augment.append(tio.RandomAffine())\n",
    "                elif a == 'noise':\n",
    "                    augment.append(tio.RandomNoise(p=0.3))\n",
    "\n",
    "                elif a == 'motion':\n",
    "                    augment.append(tio.RandomMotion(p=0.2))\n",
    "\n",
    "            augment = tio.Compose(augment)\n",
    "            return augment\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "\n",
    "\n",
    "        indices = range(self.n_train) #np.random.choice(range(self.n_train), range(self.n_train), replace=False)\n",
    "        split = int(np.floor(.2 * self.n_train))\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "        # Creating PT data samplers and loaders:\n",
    "        if self.sampler is not True:\n",
    "            self.train_sampler = SubsetRandomSampler(train_indices)\n",
    "            self.val_sampler = SubsetRandomSampler(val_indices)\n",
    "        else:\n",
    "\n",
    "            self.train_sampler, self.pos_weight = class_imbalance_sampler(self.train_labels[train_indices])\n",
    "\n",
    "\n",
    "        train_subjects = [self.subjects[i] for i in train_indices]\n",
    "        val_subjects = [self.subjects[i] for i in val_indices]\n",
    "\n",
    "        self.preprocess = self.get_preprocessing_transform()\n",
    "        augment = self.get_augmentation_transform()\n",
    "        if augment is not None:\n",
    "            self.transform = tio.Compose([self.preprocess, augment])\n",
    "        else:\n",
    "            self.transform = self.preprocess\n",
    "\n",
    "        self.train_set = tio.SubjectsDataset(train_subjects, transform=self.transform)\n",
    "        self.val_set = tio.SubjectsDataset(val_subjects, transform=self.preprocess)\n",
    "        self.test_set = tio.SubjectsDataset(self.test_subjects, transform=self.preprocess)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, self.batch_size, sampler=self.train_sampler, num_workers=self.num_workers, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, self.batch_size, num_workers=self.num_workers, drop_last=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, self.batch_size)\n",
    "    \n",
    "\n",
    "def get_mri_data_beta(N,data_dir,cropped=False,test=False):\n",
    "\n",
    "    name = f\"data_split_c.csv\"\n",
    "    df = pd.read_csv(os.path.join(data_dir, name))\n",
    "    labels = []\n",
    "\n",
    "    dfg = df.groupby(\"class\")\n",
    "    data = []\n",
    "    for name, subdata in dfg:\n",
    "        print(f\"Group: {name}\")\n",
    "        # shuffle\n",
    "        K = subdata.shape[0]\n",
    "        shuffled_ind = np.random.choice(range(K),len(range(K)),replace=False)\n",
    "        #subsample\n",
    "        shuffled_ind = shuffled_ind[:N]\n",
    "        data.extend(subdata[\"filename\"].values[shuffled_ind])\n",
    "        labels.extend(subdata[\"class\"].values[shuffled_ind])\n",
    "\n",
    "    # shuffle\n",
    "    data = np.array(data).reshape(-1)\n",
    "    labels=np.array(labels).reshape(-1)\n",
    "    ind = np.random.choice(len(labels),len(labels),replace=False)\n",
    "\n",
    "    labels = labels[ind]\n",
    "    data= data[ind]\n",
    "\n",
    "    assert data.shape[0] == labels.shape[0]\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f686787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(pl.LightningModule):\n",
    "    def __init__(self, features, **conf):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"features\"])\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((7,7,7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, self.hparams.num_classes),\n",
    "        )\n",
    "        #if init_weights:\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch['image'][tio.DATA]\n",
    "        y = batch['label']\n",
    "        raw_out = self(x)\n",
    "        loss = self.loss(raw_out, y)\n",
    "        preds = torch.argmax(torch.softmax(raw_out, dim=1), dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        #print(f\"Train Loss: {loss}\")\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x = batch['image'][tio.DATA]\n",
    "        y = batch['label']\n",
    "        raw_out = self(x)\n",
    "        loss = self.loss(raw_out, y)\n",
    "        preds = torch.argmax(torch.softmax(raw_out, dim=1), dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # self.hparams available because we called self.save_hyperparameters()\n",
    "        if self.hparams.optim == 'adam':\n",
    "            optim = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate,weight_decay=1e-4)\n",
    "        elif self.hparams.optim == 'sgd':\n",
    "            optim = torch.optim.SGD(self.parameters(), lr=self.hparams.learning_rate, weight_decay=1e-4)\n",
    "        elif  self.hparams.optim == 'adamw':\n",
    "            optim = torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optim,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": ExponentialLR(optim, gamma=0.9), #ReduceLROnPlateau(optim, ...),\n",
    "                \"monitor\": \"valid_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"VGGNet\")\n",
    "        parser.add_argument('--learning_rate', type=float, default=0.001)\n",
    "        parser.add_argument('--dropout', type=float, default=0.5)\n",
    "        parser.add_argument('--name', type=str, default='vggnet')\n",
    "        parser.add_argument('--optim', type=str, default='adam')\n",
    "        return parent_parser        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df429703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool3d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv3d = nn.Conv3d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv3d, nn.BatchNorm3d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv3d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21fca04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = {\n",
    "    'A': [8, 'M', 16, 'M', 32, 32, 'M', 64, 64, 'M'],\n",
    "    #'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f69b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vgg(arch, cfg, batch_norm, pretrained, progress, hparams):\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **hparams)\n",
    "    if pretrained:\n",
    "        pass\n",
    "       #state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                #                              progress=progress)\n",
    "        #model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def vgg11(pretrained=False, progress=True, hparams={}):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "\n",
    "    Args:\n",
    "       \tpretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "       \tprogress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg11', 'A', False, pretrained, progress, hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1873ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: 0\n",
      "Group: 1\n",
      "Group: 2\n",
      "Group: 3\n",
      "Group: 4\n",
      "Class distribution in test set: tensor([ 61, 105,  11,  13,  40])\n",
      "Class distribution in train set: tensor([582, 892, 165, 120, 305])\n",
      "Class_count: tensor([462, 729, 139,  92, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/spinney/env/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape used: [172 176 218]\n"
     ]
    }
   ],
   "source": [
    "args = {'data_dir': '/scratch/spinney/enigma_drug/data',\n",
    "       'batch_size': 16,\n",
    "       'num_classes': 5,\n",
    "       'num_workers': 4,\n",
    "       'num_samples': -1,\n",
    "       'seed': 0,\n",
    "       'format': 'nifti',\n",
    "       'test': False,\n",
    "       'cropped': True,\n",
    "       'augment': None,\n",
    "       'learning_rate': 0.001,\n",
    "       'dropout': 0.5,\n",
    "       'name': 'vggnet',\n",
    "       'optim': 'adam',\n",
    "       'max_epochs': 20}\n",
    "\n",
    "# set global seed\n",
    "pl.seed_everything(args['seed'])\n",
    "\n",
    "mask = ''\n",
    "\n",
    "if args['num_samples'] == -1:\n",
    "    args['num_samples'] = -1*args['num_classes']\n",
    "\n",
    "# these are returned shuffled\n",
    "file_paths, labels = get_mri_data_beta(args['num_samples']//args['num_classes'], args['data_dir'], cropped=args['cropped'], test=False)\n",
    "\n",
    "dm = MRIDataModuleIO(args['data_dir'], labels, args['format'], args['batch_size'], args['augment'], mask, file_paths, args['num_workers'])\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "\n",
    "print(f\"Input shape used: {dm.max_shape}\")\n",
    "dict_args = args\n",
    "dict_args['pos_weight'] = dm.pos_weight\n",
    "dict_args['input_shape'] = dm.max_shape\n",
    "dict_args['class_names'] = [\"control\",\"ALC\",\"ATS\",\"COC\",\"NIC\"] \n",
    "slurm = os.environ.get(\"SLURM_JOB_NUM_NODES\")\n",
    "num_nodes = int(slurm) if slurm else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b141136",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16725/3681828017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16725/3826407307.py\u001b[0m in \u001b[0;36mvgg11\u001b[0;34m(pretrained, progress, hparams)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplays\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16725/3826407307.py\u001b[0m in \u001b[0;36m_vgg\u001b[0;34m(arch, cfg, batch_norm, pretrained, progress, hparams)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16725/2870853171.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, features, **conf)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/spinney/env/lib/python3.7/site-packages/pytorch_lightning/core/mixins/hparams_mixin.py\u001b[0m in \u001b[0;36msave_hyperparameters\u001b[0;34m(self, ignore, frame, logger, *args)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0msave_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/spinney/env/lib/python3.7/site-packages/pytorch_lightning/utilities/parsing.py\u001b[0m in \u001b[0;36msave_hyperparameters\u001b[0;34m(obj, ignore, frame, *args)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mcand_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcand_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcand_names\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/spinney/env/lib/python3.7/site-packages/pytorch_lightning/utilities/parsing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mcand_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcand_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcand_names\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "dm.pos_weight\n",
    "model = vgg11(pretrained=False, progress=True, hparams=dict_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "445c1f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16725/2529815309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer = pl.Trainer(default_root_dir=\"/scratch/spinney/enigma_drug/checkpoints/\",\n\u001b[1;32m      4\u001b[0m                      \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16725/1687746953.py\u001b[0m in \u001b[0;36mvgg11\u001b[0;34m(pretrained, progress, hparams)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplays\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16725/1687746953.py\u001b[0m in \u001b[0;36m_vgg\u001b[0;34m(arch, cfg, batch_norm, pretrained, progress, hparams)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer = pl.Trainer(default_root_dir=\"/scratch/spinney/enigma_drug/checkpoints/\",\n",
    "                     gpus=torch.cuda.device_count(),\n",
    "                     num_nodes=num_nodes,\n",
    "                     strategy='ddp' if num_nodes > 1 else 'dp',\n",
    "                     max_epochs=args['max_epochs'],\n",
    "                     log_every_n_steps=10,\n",
    "#                     logger=wandb_logger,\n",
    "                     replace_sampler_ddp=False)#,\n",
    "                     #precision=16)\n",
    "                     #early_stop_callback=False)\n",
    "                     #callbacks=[early_stopping_callback])\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# ------------\n",
    "# testing\n",
    "# ------------\n",
    "\n",
    "dm.setup(stage='test')\n",
    "trainer.test(datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83feb8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 DEEP",
   "language": "python",
   "name": "cedar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
